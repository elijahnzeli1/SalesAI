# -*- coding: utf-8 -*-
"""SalesAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nEp1yp07HUIa-HaKUsuI0zL46AAzzU5p
"""

# SalesA AI - Complete Multimodal AI System Implementation
# Created by: SalesA Team
# A lightweight, CPU-optimized multimodal AI with MoE architecture

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Union, Any
import json
import os
from pathlib import Path
import logging
from dataclasses import dataclass
import math
import random
from collections import OrderedDict
import torchvision.transforms as transforms
from PIL import Image
import torchaudio
import re
import pickle
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
from safetensors.torch import save_file # Import save_file
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import tiktoken  # Add this import at the top
from huggingface_hub import snapshot_download
from config import SalesAConfig
from model.moe import Expert, Router, MoELayer
from model.encoders import TextEncoder, VisionEncoder, AudioEncoder
from model.transformer import MultiHeadAttention, TransformerBlock
from model.salesa_model import SalesAModel
from data.dataset import MultimodalDataset
from data.collate import collate_fn, create_multimodal_dataloaders
from rl.agent import AGIEnvironment, SimpleTextEnv, ReplayBuffer, EpisodicMemory, QNetwork, DQNAgent

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

"""# 1. CONFIGURATION AND HYPERPARAMETERS"""

@dataclass
class SalesAConfig:
    """Configuration class for SalesA AI"""
    # Model architecture
    vocab_size: int = 32000
    hidden_dim: int = 512  # Reduced for CPU efficiency
    num_layers: int = 8    # Reduced for CPU efficiency
    num_heads: int = 8
    intermediate_dim: int = 1024
    max_seq_len: int = 2048

    # MoE configuration
    num_experts: int = 4   # Reduced for CPU efficiency
    expert_capacity: int = 2
    top_k: int = 2

    # Multimodal dimensions
    vision_dim: int = 224
    audio_dim: int = 80
    vision_patch_size: int = 16
    audio_patch_size: int = 4

    # Training parameters
    batch_size: int = 4    # Small batch for CPU
    learning_rate: float = 1e-4
    weight_decay: float = 1e-5
    dropout_rate: float = 0.1

    # Optimization for CPU
    use_mixed_precision: bool = False  # CPU doesn't support AMP well
    gradient_checkpointing: bool = True

    # Data parameters
    max_text_length: int = 1024
    max_audio_length: int = 16000  # 1 second at 16kHz
    action_dim: int = 10  # Number of possible actions for robotics

    model_name: str = "SalesA AI"
    model_author: str = "Created by N.E.N (Nthuku Elijah Nzeli) and SalesA Team"

    def __post_init__(self):
        """Validate configuration"""
        assert self.hidden_dim % self.num_heads == 0, "hidden_dim must be divisible by num_heads"
        assert self.top_k <= self.num_experts, "top_k must be <= num_experts"

"""# 5. MAIN SALESA AI MODEL:"""

"""# 6. DATASET CLASSES"""

from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn.functional as F
import random
import logging
from typing import Dict, List, Optional, Union
import torchvision.transforms as transforms
from PIL import Image
import torchaudio
from datasets import load_dataset
import numpy as np
import io
import soundfile as sf  # Added for audio decoding

logger = logging.getLogger(__name__)

"""# 12. ADDITIONAL UTILITIES AND HELPERS"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Union
import json
import os
from pathlib import Path
import logging
from dataclasses import dataclass
import math
import random
from collections import OrderedDict
import torchvision.transforms as transforms
from PIL import Image
import torchaudio
import re
import pickle
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
from safetensors.torch import save_file # Import save_file

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def export_for_deployment(model: SalesAModel, config: SalesAConfig, tokenizer: SalesATokenizer, export_dir: str = "./SalesA"):
    """Export model and assets for deployment (Hugging Face compatible)"""
    os.makedirs(export_dir, exist_ok=True)

    # 1. Save model weights in safetensors format
    model_path = os.path.join(export_dir, "model.safetensors")
    save_file(model.state_dict(), model_path)

    # 2. Save config as JSON
    config_path = os.path.join(export_dir, "config.json")
    with open(config_path, "w") as f:
        json.dump(config.__dict__, f, indent=2)

    # 3. Save tokenizer files
    tokenizer_json = {
        "vocab": tokenizer.vocab,
        "token_to_id": tokenizer.token_to_id,
        "id_to_token": tokenizer.id_to_token,
        "pad_token": tokenizer.pad_token,
        "unk_token": tokenizer.unk_token,
        "bos_token": tokenizer.bos_token,
        "eos_token": tokenizer.eos_token,
        "code_token": tokenizer.code_token,
        "pad_token_id": tokenizer.pad_token_id,
        "unk_token_id": tokenizer.unk_token_id,
        "bos_token_id": tokenizer.bos_token_id,
        "eos_token_id": tokenizer.eos_token_id,
        "code_token_id": tokenizer.code_token_id,
        "model_author": config.model_author
    }
    tokenizer_path = os.path.join(export_dir, "tokenizer.json")
    with open(tokenizer_path, "w") as f:
        json.dump(tokenizer_json, f, indent=2)

    # 4. Save training arguments/metadata
    training_args = {
        "learning_rate": config.learning_rate,
        "weight_decay": config.weight_decay,
        "dropout_rate": config.dropout_rate,
        "batch_size": config.batch_size,
        "num_epochs": 10 # Updated epochs to match main execution
        # Add other relevant training parameters here
    }
    training_args_path = os.path.join(export_dir, "training_args.json")
    with open(training_args_path, "w") as f:
        json.dump(training_args, f, indent=2)
    print(f"✓ Training arguments saved to {training_args_path}")

    # --- Additional required files ---
    # 1. merge.txt (for tokenizer merges, placeholder if not used)
    merge_path = os.path.join(export_dir, "merge.txt")
    with open(merge_path, "w") as f:
        f.write("# Placeholder for tokenizer merges (if using BPE or similar)\n")
    # 2. README.md
    readme_path = os.path.join(export_dir, "README.md")
    with open(readme_path, "w") as f:
        f.write(f"Created by: {config.model_author}\n\n")
        f.write("""# SalesA AI Model\n\nThis directory contains the SalesA AI multimodal model, tokenizer, and all associated files for deployment and inference.\n\n- Model weights: model.safetensors\n- Config: config.json\n- Tokenizer: tokenizer.json, vocab.json, tokenizer.model\n- Generation config: generation_config.json\n- Merge file: merge.txt\n- Index: model.safetensors.index.json\n- Chat template: chat_template.jinja\n\nFor more details, see the documentation.\n""")
    # 3. chat_template.jinja (template for chat UIs, placeholder)
    chat_template_path = os.path.join(export_dir, "chat_template.jinja")
    with open(chat_template_path, "w") as f:
        f.write("""{# Jinja2 template for chat formatting #}\n{{ user }}: {{ message }}\n""")
    # 4. generation_config.json (default generation parameters)
    generation_config_path = os.path.join(export_dir, "generation_config.json")
    generation_config = {
        "max_length": 128,
        "temperature": 0.7,
        "top_k": 50,
        "do_sample": True
    }
    with open(generation_config_path, "w") as f:
        json.dump(generation_config, f, indent=2)
    # 5. model.safetensors.index.json (index file for sharded weights, placeholder)
    index_path = os.path.join(export_dir, "model.safetensors.index.json")
    with open(index_path, "w") as f:
        json.dump({"weight_map": {"model.safetensors": []}}, f, indent=2)
    # 6. tokenizer.model (placeholder for SentencePiece or similar)
    tokenizer_model_path = os.path.join(export_dir, "tokenizer.model")
    with open(tokenizer_model_path, "wb") as f:
        f.write(b"# Placeholder for tokenizer.model (e.g., SentencePiece)")
    print(f"✓ Model exported to {export_dir} (model.safetensors, config.json, tokenizer.json, training_args.json, merge.txt, README.md, chat_template.jinja, generation_config.json, model.safetensors.index.json, tokenizer.model)")

def find_max_batch_size(model, input_shape, labels_shape, optimizer, loss_fn, device, max_batch=128, target_effective_batch=32):
    """
    Find the largest batch size that fits in memory for the given model and input shape.
    Returns (batch_size, gradient_accumulation_steps) to reach at least target_effective_batch.
    """
    batch_size = 2
    last_good = 2
    while batch_size <= max_batch:
        try:
            dummy_input = torch.randint(0, model.config.vocab_size, (batch_size, input_shape), device=device)
            dummy_labels = torch.randint(0, model.config.vocab_size, (batch_size, labels_shape), device=device)
            optimizer.zero_grad()
            output = model(input_ids=dummy_input, labels=dummy_labels, task_type="text", return_loss=True)
            loss = output["loss"] if isinstance(output, dict) else output
            loss.backward()
            optimizer.step()
            last_good = batch_size
            batch_size *= 2
        except RuntimeError as e:
            if 'out of memory' in str(e):
                if hasattr(torch.cuda, 'empty_cache'):
                    torch.cuda.empty_cache()
                break
            else:
                raise e
    grad_accum = max(1, target_effective_batch // last_good)
    return last_good, grad_accum


"""# 13. EXECUTION ENTRY **POINT**"""

 # Call the original main function for standard environment
if __name__ == "__main__":
    main() 