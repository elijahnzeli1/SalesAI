{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ SalesAI - Multimodal Generative AI Training Notebook\n",
    "\n",
    "**Complete training pipeline for the SalesAI multimodal AGI-like model with GPU acceleration**\n",
    "\n",
    "This notebook provides a comprehensive training pipeline for the SalesAI multimodal generative AI model, optimized for Google Colab with GPU acceleration.\n",
    "\n",
    "## üéØ What this notebook does:\n",
    "\n",
    "1. **Environment Setup**: Install all required dependencies\n",
    "2. **Repository Setup**: Clone the SalesAI codebase to Google Drive\n",
    "3. **Model Training**: Train the multimodal model with GPU acceleration\n",
    "4. **Evaluation**: Comprehensive model evaluation and analysis\n",
    "5. **Model Saving**: Save trained model and artifacts\n",
    "6. **Inference**: Test the trained model\n",
    "\n",
    "## üèóÔ∏è Model Architecture:\n",
    "- **Multimodal Encoders**: Text, Vision, and Audio processing\n",
    "- **Unified Transformer Backbone**: Cross-modal attention with MoE\n",
    "- **Reinforcement Learning**: DQN agent for autonomous learning\n",
    "- **Meta-Learning**: Rapid task adaptation capabilities\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: N.E.N (Nthuku Elijah Nzeli) and SalesA Team  \n",
    "**Model**: SalesA AI - Multimodal AGI-like Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üìã Prerequisites and Setup\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. **Google Colab Pro** (recommended for better GPU access)\n",
    "2. **Google Drive** connected\n",
    "3. **GitHub repository access**\n",
    "\n",
    "### Runtime Configuration:\n",
    "- **Hardware accelerator**: GPU (T4, V100, or A100)\n",
    "- **Runtime type**: Python 3\n",
    "- **RAM**: 16GB+ (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability and configuration\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîç Checking system configuration...\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"‚úÖ Using GPU: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, using CPU (training will be slower)\")\n",
    "\n",
    "# Check available memory\n",
    "import psutil\n",
    "print(f\"RAM available: {psutil.virtual_memory().total / 1e9:.1f} GB\")\n",
    "print(f\"RAM free: {psutil.virtual_memory().available / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_deps"
   },
   "source": [
    "## üì¶ Step 1: Install Dependencies\n",
    "\n",
    "Install all required packages for the SalesAI model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "print(\"üì¶ Installing system dependencies...\")\n",
    "!apt-get update -qq\n",
    "!apt-get install -y ffmpeg\n",
    "\n",
    "# Install Python packages\n",
    "print(\"\\nüì¶ Installing Python packages...\")\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers datasets tiktoken\n",
    "!pip install -q scikit-learn numpy matplotlib tqdm\n",
    "!pip install -q Pillow safetensors torchcodec\n",
    "!pip install -q soundfile seaborn psutil\n",
    "!pip install -q accelerate bitsandbytes\n",
    "!pip install -q wandb tensorboard\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount_drive"
   },
   "source": [
    "## üìÅ Step 2: Mount Google Drive and Setup Repository\n",
    "\n",
    "Mount Google Drive and clone the SalesAI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_google_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"üìÅ Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory\n",
    "project_dir = \"/content/drive/MyDrive/SalesAI_Project\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "os.chdir(project_dir)\n",
    "\n",
    "print(f\"üìÇ Project directory: {project_dir}\")\n",
    "print(f\"üìÇ Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the SalesAI repository\n",
    "# Replace with your actual repository URL\n",
    "repo_url = \"https://github.com/your-username/SalesAI.git\"  # Update this URL\n",
    "\n",
    "print(f\"üì• Cloning repository: {repo_url}\")\n",
    "!git clone {repo_url} SalesAI\n",
    "\n",
    "# Navigate to the project directory\n",
    "os.chdir(\"SalesAI\")\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# List project files\n",
    "print(\"\\nüìã Project structure:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify_setup"
   },
   "source": [
    "## ‚úÖ Step 3: Verify Setup and Import Modules\n",
    "\n",
    "Verify that all modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_imports"
   },
   "outputs": [],
   "source": [
    "# Add current directory to Python path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# Test imports\n",
    "print(\"üîç Testing imports...\")\n",
    "\n",
    "try:\n",
    "    from config import SalesAConfig\n",
    "    from model.salesa_model import SalesAModel\n",
    "    from tokenizer import SalesATokenizer\n",
    "    from data.dataset import MultimodalDataset\n",
    "    from train import SalesATrainer\n",
    "    from evaluate import SalesAEvaluator\n",
    "    from rl.agent import DQNAgent, SimpleTextEnv\n",
    "    \n",
    "    print(\"‚úÖ All core modules imported successfully!\")\n",
    "    \n",
    "    # Test configuration\n",
    "    config = SalesAConfig()\n",
    "    print(f\"‚úÖ Configuration loaded: {config.model_name}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Please check the repository structure and file paths.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep"
   },
   "source": [
    "## üìä Step 4: Data Preparation and Dataset Setup\n",
    "\n",
    "Prepare datasets for multimodal training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_datasets"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tokenizer import build_vocab_with_tiktoken, SalesATokenizer\n",
    "from data.dataset import MultimodalDataset\n",
    "from data.collate import create_multimodal_dataloaders\n",
    "\n",
    "print(\"üìä Setting up datasets...\")\n",
    "\n",
    "# Load all supported datasets with full multimodal support\n",
    "datasets_to_load = [\n",
    "    \"luma\",           # Multimodal dataset (audio+text)\n",
    "    \"beans\",          # Image classification dataset (vision+text)\n",
    "    \"humaneval\"       # Code generation dataset (text)\n",
    "]\n",
    "\n",
    "print(f\"üì• Loading {len(datasets_to_load)} datasets...\")\n",
    "\n",
    "# Initialize basic tokenizer first\n",
    "tokenizer = SalesATokenizer(vocab_size=32000)\n",
    "\n",
    "# Create raw dataset with error handling\n",
    "try:\n",
    "    raw_dataset = MultimodalDataset(\n",
    "        config=SalesAConfig(),\n",
    "        tokenizer=tokenizer,\n",
    "        split=\"train\",\n",
    "        dataset_name=datasets_to_load\n",
    "    )\n",
    "    \n",
    "    # Build vocabulary with error handling\n",
    "    print(\"üî§ Building vocabulary...\")\n",
    "    try:\n",
    "        # Get some samples for vocabulary building\n",
    "        samples_for_vocab = []\n",
    "        for i in range(min(50, len(raw_dataset))):\n",
    "            try:\n",
    "                sample = raw_dataset[i]\n",
    "                if sample and \"text\" in sample:\n",
    "                    samples_for_vocab.append(sample)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if samples_for_vocab:\n",
    "            vocab, enc = build_vocab_with_tiktoken(\n",
    "                samples_for_vocab,\n",
    "                vocab_size=32000,\n",
    "                model_name=\"gpt2\"\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"No valid samples found for vocabulary building\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Vocabulary building error: {e}\")\n",
    "        print(\"üîÑ Using fallback vocabulary...\")\n",
    "        # Create basic vocabulary as fallback\n",
    "        vocab = {\"<pad>\": 0, \"<unk>\": 1, \"<bos>\": 2, \"<eos>\": 3, \"<code>\": 4}\n",
    "        enc = None\n",
    "    \n",
    "    # Update tokenizer with built vocabulary\n",
    "    tokenizer = SalesATokenizer(\n",
    "        vocab_size=32000,\n",
    "        vocab=vocab,\n",
    "        enc=enc\n",
    "    )\n",
    "    \n",
    "    # Fix vocab length calculation\n",
    "    if isinstance(vocab, dict):\n",
    "        vocab_length = len(vocab)\n",
    "    elif isinstance(vocab, list):\n",
    "        vocab_length = len(vocab)\n",
    "    else:\n",
    "        vocab_length = len(list(vocab)) if hasattr(vocab, '__iter__') else 0\n",
    "    \n",
    "    print(f\"‚úÖ Vocabulary built with {vocab_length} tokens\")\n",
    "    print(f\"‚úÖ Tokenizer initialized successfully\")\n",
    "    print(f\"‚úÖ Multimodal datasets loaded: Audio, Vision, and Text processing enabled\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Dataset error: {e}\")\n",
    "    print(\"üîÑ Using synthetic data...\")\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1, \"<bos>\": 2, \"<eos>\": 3, \"<code>\": 4}\n",
    "    tokenizer = SalesATokenizer(vocab_size=32000, vocab=vocab, enc=None)\n",
    "    print(f\"‚úÖ Fallback tokenizer created with {len(vocab)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_dataloaders"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders for training\n",
    "print(\"üîÑ Creating dataloaders...\")\n",
    "\n",
    "# Load configuration\n",
    "from utils.config import load_config\n",
    "config = load_config(\"multimodal\")\n",
    "\n",
    "# Update config for GPU training\n",
    "config.training.batch_size = 4  # Adjust based on GPU memory\n",
    "config.training.use_mixed_precision = True\n",
    "config.training.gradient_accumulation_steps = 8\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_multimodal_dataloaders(\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=config.training.batch_size,\n",
    "    dataset_name=datasets_to_load,\n",
    "    task_type=\"multimodal\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training dataloader: {len(train_loader)} batches\")\n",
    "print(f\"‚úÖ Validation dataloader: {len(val_loader)} batches\")\n",
    "\n",
    "# Test a batch\n",
    "print(\"\\nüß™ Testing data loading...\")\n",
    "for batch in train_loader:\n",
    "    print(f\"Batch keys: {list(batch.keys())}\")\n",
    "    if 'input_ids' in batch:\n",
    "        print(f\"Input shape: {batch['input_ids'].shape}\")\n",
    "    if 'images' in batch:\n",
    "        print(f\"Images shape: {batch['images'].shape}\")\n",
    "    if 'audio' in batch:\n",
    "        print(f\"Audio shape: {batch['audio'].shape}\")\n",
    "    break\n",
    "\n",
    "print(\"‚úÖ Data loading test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_init"
   },
   "source": [
    "## üß† Step 5: Initialize Model\n",
    "\n",
    "Initialize the SalesAI multimodal model with GPU optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_model"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.salesa_model import SalesAModel\n",
    "\n",
    "print(\"üß† Initializing SalesAI model...\")\n",
    "\n",
    "# Initialize model with GPU-optimized configuration\n",
    "model = SalesAModel(config)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Enable mixed precision training\n",
    "if config.training.use_mixed_precision:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    scaler = GradScaler()\n",
    "    print(\"‚úÖ Mixed precision training enabled\")\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "# Print model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"üìä Model Information:\")\n",
    "print(f\"   - Total parameters: {total_params:,}\")\n",
    "print(f\"   - Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   - Model size: {total_params * 4 / 1e6:.1f} MB\")\n",
    "print(f\"   - Device: {next(model.parameters()).device}\")\n",
    "print(f\"   - Mixed precision: {config.training.use_mixed_precision}\")\n",
    "\n",
    "# Test model forward pass\n",
    "print(\"\\nüß™ Testing model forward pass...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Create dummy input\n",
    "    batch_size = 2\n",
    "    seq_len = 128\n",
    "    \n",
    "    input_ids = torch.randint(0, config.model.vocab_size, (batch_size, seq_len)).to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "    \n",
    "    # Test text-only forward pass\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        task_type=\"text\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Forward pass successful!\")\n",
    "    print(f\"   - Output shape: {outputs.logits.shape}\")\n",
    "    print(f\"   - Hidden states shape: {outputs.hidden_states[-1].shape}\")\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üöÄ Step 6: Model Training\n",
    "\n",
    "Train the SalesAI model with comprehensive monitoring and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_training"
   },
   "outputs": [],
   "source": [
    "from train import SalesATrainer\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"üöÄ Setting up training...\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = SalesATrainer(config)\n",
    "trainer.model = model\n",
    "trainer.tokenizer = tokenizer\n",
    "\n",
    "# Setup optimizer with weight decay\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() \n",
    "                   if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': config.training.weight_decay\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() \n",
    "                   if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=config.training.learning_rate,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Setup learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=len(train_loader) * config.training.num_epochs,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "trainer.optimizer = optimizer\n",
    "trainer.scheduler = scheduler\n",
    "trainer.scaler = scaler\n",
    "\n",
    "print(f\"‚úÖ Optimizer: AdamW with lr={config.training.learning_rate}\")\n",
    "print(f\"‚úÖ Scheduler: CosineAnnealingLR\")\n",
    "print(f\"‚úÖ Mixed precision: {config.training.use_mixed_precision}\")\n",
    "print(f\"‚úÖ Gradient accumulation steps: {config.training.gradient_accumulation_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_loop"
   },
   "outputs": [],
   "source": [
    "# Training loop with progress tracking\n",
    "print(\"üöÄ Starting training loop...\")\n",
    "\n",
    "# Training metrics\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'learning_rate': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Training epochs\n",
    "for epoch in range(config.training.num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nüìÖ Epoch {epoch + 1}/{config.training.num_epochs}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_pbar):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        if config.training.use_mixed_precision:\n",
    "            with autocast():\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "        else:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "        \n",
    "        # Scale loss for gradient accumulation\n",
    "        loss = loss / config.training.gradient_accumulation_steps\n",
    "        \n",
    "        # Backward pass\n",
    "        if config.training.use_mixed_precision:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (batch_idx + 1) % config.training.gradient_accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            if config.training.use_mixed_precision:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.training.gradient_clip_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.training.gradient_clip_norm)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += loss.item() * config.training.gradient_accumulation_steps\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        })\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}\")\n",
    "        \n",
    "        for batch in val_pbar:\n",
    "            # Move batch to device\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                    for k, v in batch.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            val_pbar.set_postfix({'val_loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Update history\n",
    "    training_history['train_loss'].append(avg_train_loss)\n",
    "    training_history['val_loss'].append(avg_val_loss)\n",
    "    training_history['learning_rate'].append(scheduler.get_last_lr()[0])\n",
    "    \n",
    "    # Print epoch summary\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"\\nüìä Epoch {epoch + 1} Summary:\")\n",
    "    print(f\"   - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   - Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"   - Learning Rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    print(f\"   - Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'config': config\n",
    "        }, f'/content/drive/MyDrive/SalesAI_Project/best_model_epoch_{epoch + 1}.pt')\n",
    "        print(f\"   - üíæ Best model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"   - ‚è≥ Early stopping patience: {patience_counter}/{config.training.early_stopping_patience}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config.training.early_stopping_patience:\n",
    "        print(f\"\\nüõë Early stopping triggered after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"\\nüéâ Training completed in {total_training_time / 3600:.1f} hours\")\n",
    "print(f\"üìä Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_plots"
   },
   "source": [
    "## üìà Step 7: Training Visualization\n",
    "\n",
    "Visualize training progress and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_training"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create training plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('SalesAI Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Training and Validation Loss\n",
    "axes[0, 0].plot(training_history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(training_history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Learning Rate\n",
    "axes[0, 1].plot(training_history['learning_rate'], color='green', linewidth=2)\n",
    "axes[0, 1].set_title('Learning Rate Schedule')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Learning Rate')\n",
    "axes[0, 1].set_yscale('log')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Loss Difference\n",
    "loss_diff = np.array(training_history['train_loss']) - np.array(training_history['val_loss'])\n",
    "axes[1, 0].plot(loss_diff, color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_title('Train-Val Loss Difference')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss Difference')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Loss Ratio\n",
    "loss_ratio = np.array(training_history['val_loss']) / np.array(training_history['train_loss'])\n",
    "axes[1, 1].plot(loss_ratio, color='purple', linewidth=2)\n",
    "axes[1, 1].axhline(y=1, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_title('Validation/Train Loss Ratio')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss Ratio')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plots\n",
    "plt.savefig('/content/drive/MyDrive/SalesAI_Project/training_plots.png', dpi=300, bbox_inches='tight')\n",
    "print(\"üìä Training plots saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## üîç Step 8: Model Evaluation\n",
    "\n",
    "Comprehensive evaluation of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_best_model"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "print(\"üîç Loading best model for evaluation...\")\n",
    "\n",
    "# Find the best model checkpoint\n",
    "import glob\n",
    "checkpoint_files = glob.glob('/content/drive/MyDrive/SalesAI_Project/best_model_epoch_*.pt')\n",
    "if checkpoint_files:\n",
    "    # Get the latest checkpoint\n",
    "    latest_checkpoint = max(checkpoint_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"‚úÖ Loaded checkpoint: {latest_checkpoint}\")\n",
    "    print(f\"   - Epoch: {checkpoint['epoch'] + 1}\")\n",
    "    print(f\"   - Best validation loss: {checkpoint['best_val_loss']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No checkpoint found, using current model state\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "text_generation_eval"
   },
   "outputs": [],
   "source": [
    "# Text generation evaluation\n",
    "print(\"üìù Evaluating text generation capabilities...\")\n",
    "\n",
    "from evaluate import SalesAEvaluator\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = SalesAEvaluator(model, tokenizer)\n",
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"In a world where technology continues to evolve\",\n",
    "    \"Machine learning algorithms can\",\n",
    "    \"The most important aspect of AGI is\",\n",
    "    \"When we think about multimodal AI\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Text Generation Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\nüìù Prompt {i}: {prompt}\")\n",
    "    \n",
    "    # Generate text\n",
    "    generated_text = evaluator.generate_text(\n",
    "        prompt=prompt,\n",
    "        max_length=100,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    print(f\"ü§ñ Generated: {generated_text}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = evaluator.evaluate_text_quality(generated_text)\n",
    "    print(f\"üìä Metrics: Fluency={metrics['fluency']:.2f}, Coherence={metrics['coherence']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "code_generation_eval"
   },
   "outputs": [],
   "source": [
    "# Code generation evaluation\n",
    "print(\"\\nüíª Evaluating code generation capabilities...\")\n",
    "\n",
    "code_prompts = [\n",
    "    \"Write a function to calculate fibonacci numbers\",\n",
    "    \"Create a class for a binary tree data structure\",\n",
    "    \"Implement a quicksort algorithm\",\n",
    "    \"Write a function to find the longest common subsequence\",\n",
    "    \"Create a simple neural network class\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Code Generation Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, prompt in enumerate(code_prompts, 1):\n",
    "    print(f\"\\nüíª Code Prompt {i}: {prompt}\")\n",
    "    \n",
    "    # Generate code\n",
    "    generated_code = evaluator.generate_code(\n",
    "        prompt=prompt,\n",
    "        max_length=200,\n",
    "        temperature=0.3,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    print(f\"ü§ñ Generated Code:\")\n",
    "    print(f\"```python\")\n",
    "    print(generated_code)\n",
    "    print(f\"```\")\n",
    "    \n",
    "    # Evaluate code quality\n",
    "    code_metrics = evaluator.evaluate_code_quality(generated_code)\n",
    "    print(f\"üìä Code Metrics: Syntax={code_metrics['syntax_valid']}, Completeness={code_metrics['completeness']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "expert_analysis"
   },
   "outputs": [],
   "source": [
    "# Expert usage analysis\n",
    "print(\"\\nüî¨ Analyzing MoE expert usage...\")\n",
    "\n",
    "# Get expert usage statistics\n",
    "expert_stats = evaluator.analyze_expert_usage()\n",
    "\n",
    "print(f\"üìä Expert Usage Analysis for {len(expert_stats)} layers:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create expert usage visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('MoE Expert Usage Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, stats in enumerate(expert_stats[:4]):  # Show first 4 layers\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    # Expert usage distribution\n",
    "    expert_usage = stats['expert_usage']\n",
    "    axes[row, col].bar(range(len(expert_usage)), expert_usage, alpha=0.7)\n",
    "    axes[row, col].set_title(f\"Layer {stats['layer_name']} - Expert Usage\")\n",
    "    axes[row, col].set_xlabel('Expert Index')\n",
    "    axes[row, col].set_ylabel('Usage Count')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print expert statistics\n",
    "for stats in expert_stats:\n",
    "    print(f\"Layer {stats['layer_name']}:\")\n",
    "    print(f\"  - Load balance: {stats['load_balance']:.4f}\")\n",
    "    print(f\"  - Expert utilization: {stats['utilization']:.2f}%\")\n",
    "    print(f\"  - Most used expert: {stats['most_used_expert']}\")\n",
    "    print(f\"  - Least used expert: {stats['least_used_expert']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl_training"
   },
   "source": [
    "## ü§ñ Step 9: Reinforcement Learning Training\n",
    "\n",
    "Train the RL agent for autonomous learning capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_rl"
   },
   "outputs": [],
   "source": [
    "# Setup RL training\n",
    "print(\"ü§ñ Setting up Reinforcement Learning training...\")\n",
    "\n",
    "from rl.agent import DQNAgent, SimpleTextEnv\n",
    "\n",
    "# Initialize environment and agent\n",
    "env = SimpleTextEnv()\n",
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    n_actions=config.data.action_dim,\n",
    "    buffer_capacity=config.rl.buffer_capacity,\n",
    "    memory_capacity=config.rl.memory_capacity\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Environment initialized\")\n",
    "print(f\"‚úÖ RL Agent initialized with {config.rl.buffer_capacity} buffer capacity\")\n",
    "print(f\"‚úÖ Episodic memory capacity: {config.rl.memory_capacity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rl_training_loop"
   },
   "outputs": [],
   "source": [
    "# RL training loop\n",
    "print(\"ü§ñ Starting RL training...\")\n",
    "\n",
    "# RL training metrics\n",
    "rl_history = {\n",
    "    'episode_rewards': [],\n",
    "    'episode_losses': [],\n",
    "    'memory_sizes': [],\n",
    "    'buffer_sizes': [],\n",
    "    'episode_lengths': []\n",
    "}\n",
    "\n",
    "best_rl_reward = float('-inf')\n",
    "start_time = time.time()\n",
    "\n",
    "# Training episodes\n",
    "for episode in range(config.rl.num_episodes):\n",
    "    episode_start_time = time.time()\n",
    "    \n",
    "    # Train one episode\n",
    "    metrics = agent.train_episode(env)\n",
    "    \n",
    "    # Store metrics\n",
    "    rl_history['episode_rewards'].append(metrics['reward'])\n",
    "    rl_history['episode_losses'].append(metrics['avg_loss'])\n",
    "    rl_history['memory_sizes'].append(metrics['memory_size'])\n",
    "    rl_history['buffer_sizes'].append(metrics['buffer_size'])\n",
    "    rl_history['episode_lengths'].append(metrics['episode_length'])\n",
    "    \n",
    "    # Print progress\n",
    "    if (episode + 1) % 50 == 0:\n",
    "        episode_time = time.time() - episode_start_time\n",
    "        avg_reward = np.mean(rl_history['episode_rewards'][-50:])\n",
    "        avg_loss = np.mean(rl_history['episode_losses'][-50:])\n",
    "        \n",
    "        print(f\"Episode {episode + 1}/{config.rl.num_episodes}:\")\n",
    "        print(f\"  - Reward: {metrics['reward']:.2f} (Avg: {avg_reward:.2f})\")\n",
    "        print(f\"  - Loss: {metrics['avg_loss']:.4f} (Avg: {avg_loss:.4f})\")\n",
    "        print(f\"  - Memory: {metrics['memory_size']}, Buffer: {metrics['buffer_size']}\")\n",
    "        print(f\"  - Time: {episode_time:.1f}s\")\n",
    "        print()\n",
    "    \n",
    "    # Save best agent\n",
    "    if metrics['reward'] > best_rl_reward:\n",
    "        best_rl_reward = metrics['reward']\n",
    "        torch.save({\n",
    "            'episode': episode,\n",
    "            'agent_state_dict': agent.state_dict(),\n",
    "            'best_reward': best_rl_reward,\n",
    "            'config': config\n",
    "        }, f'/content/drive/MyDrive/SalesAI_Project/best_rl_agent_episode_{episode + 1}.pt')\n",
    "        print(f\"  - üíæ Best RL agent saved! (Reward: {best_rl_reward:.2f})\")\n",
    "\n",
    "total_rl_time = time.time() - start_time\n",
    "print(f\"\\nüéâ RL training completed in {total_rl_time / 3600:.1f} hours\")\n",
    "print(f\"üìä Best RL reward: {best_rl_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rl_visualization"
   },
   "outputs": [],
   "source": [
    "# RL training visualization\n",
    "print(\"üìà Visualizing RL training progress...\")\n",
    "\n",
    "# Create RL plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('RL Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Episode Rewards\n",
    "axes[0, 0].plot(rl_history['episode_rewards'], alpha=0.6, linewidth=1)\n",
    "axes[0, 0].plot(np.convolve(rl_history['episode_rewards'], np.ones(50)/50, mode='valid'), \n",
    "                color='red', linewidth=2, label='Moving Average')\n",
    "axes[0, 0].set_title('Episode Rewards')\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Reward')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Episode Losses\n",
    "axes[0, 1].plot(rl_history['episode_losses'], alpha=0.6, linewidth=1)\n",
    "axes[0, 1].plot(np.convolve(rl_history['episode_losses'], np.ones(50)/50, mode='valid'), \n",
    "                color='red', linewidth=2, label='Moving Average')\n",
    "axes[0, 1].set_title('Episode Losses')\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Memory and Buffer Sizes\n",
    "axes[0, 2].plot(rl_history['memory_sizes'], label='Memory Size', alpha=0.7)\n",
    "axes[0, 2].plot(rl_history['buffer_sizes'], label='Buffer Size', alpha=0.7)\n",
    "axes[0, 2].set_title('Memory and Buffer Usage')\n",
    "axes[0, 2].set_xlabel('Episode')\n",
    "axes[0, 2].set_ylabel('Size')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Episode Lengths\n",
    "axes[1, 0].plot(rl_history['episode_lengths'], alpha=0.6, linewidth=1)\n",
    "axes[1, 0].plot(np.convolve(rl_history['episode_lengths'], np.ones(50)/50, mode='valid'), \n",
    "                color='red', linewidth=2, label='Moving Average')\n",
    "axes[1, 0].set_title('Episode Lengths')\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Length')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Reward Distribution\n",
    "axes[1, 1].hist(rl_history['episode_rewards'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('Reward Distribution')\n",
    "axes[1, 1].set_xlabel('Reward')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Loss Distribution\n",
    "axes[1, 2].hist(rl_history['episode_losses'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 2].set_title('Loss Distribution')\n",
    "axes[1, 2].set_xlabel('Loss')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save RL plots\n",
    "plt.savefig('/content/drive/MyDrive/SalesAI_Project/rl_training_plots.png', dpi=300, bbox_inches='tight')\n",
    "print(\"üìä RL training plots saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_saving"
   },
   "source": [
    "## üíæ Step 10: Save Model and Artifacts\n",
    "\n",
    "Save the trained model, tokenizer, and all artifacts for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_model"
   },
   "outputs": [],
   "source": [
    "# Save complete model artifacts\n",
    "print(\"üíæ Saving model artifacts...\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create export directory\n",
    "export_dir = Path('/content/drive/MyDrive/SalesAI_Project/SalesAI_Model')\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = export_dir / \"model.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': config,\n",
    "    'training_history': training_history,\n",
    "    'rl_history': rl_history,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_rl_reward': best_rl_reward\n",
    "}, model_path)\n",
    "print(f\"‚úÖ Model saved to {model_path}\")\n",
    "\n",
    "# Save tokenizer\n",
    "tokenizer_path = export_dir / \"tokenizer.json\"\n",
    "tokenizer_config = {\n",
    "    \"vocab\": tokenizer.vocab,\n",
    "    \"token_to_id\": tokenizer.token_to_id,\n",
    "    \"id_to_token\": tokenizer.id_to_token,\n",
    "    \"special_tokens\": {\n",
    "        \"pad_token\": tokenizer.pad_token,\n",
    "        \"unk_token\": tokenizer.unk_token,\n",
    "        \"bos_token\": tokenizer.bos_token,\n",
    "        \"eos_token\": tokenizer.eos_token,\n",
    "        \"code_token\": tokenizer.code_token\n",
    "    }\n",
    "}\n",
    "with open(tokenizer_path, \"w\") as f:\n",
    "    json.dump(tokenizer_config, f, indent=2)\n",
    "print(f\"‚úÖ Tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config_path = export_dir / \"config.json\"\n",
    "config_dict = {\n",
    "    \"model\": {\n",
    "        \"name\": config.model.name,\n",
    "        \"author\": config.model.author,\n",
    "        \"vocab_size\": config.model.vocab_size,\n",
    "        \"hidden_dim\": config.model.hidden_dim,\n",
    "        \"num_layers\": config.model.num_layers,\n",
    "        \"num_heads\": config.model.num_heads,\n",
    "        \"num_experts\": config.model.num_experts,\n",
    "        \"top_k\": config.model.top_k\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": config.training.batch_size,\n",
    "        \"learning_rate\": config.training.learning_rate,\n",
    "        \"num_epochs\": config.training.num_epochs,\n",
    "        \"use_mixed_precision\": config.training.use_mixed_precision\n",
    "    },\n",
    "    \"rl\": {\n",
    "        \"num_episodes\": config.rl.num_episodes,\n",
    "        \"buffer_capacity\": config.rl.buffer_capacity,\n",
    "        \"memory_capacity\": config.rl.memory_capacity\n",
    "    }\n",
    "}\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "print(f\"‚úÖ Configuration saved to {config_path}\")\n",
    "\n",
    "# Save training summary\n",
    "summary_path = export_dir / \"training_summary.json\"\n",
    "training_summary = {\n",
    "    \"model_info\": {\n",
    "        \"total_parameters\": sum(p.numel() for p in model.parameters()),\n",
    "        \"trainable_parameters\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "        \"model_size_mb\": sum(p.numel() for p in model.parameters()) * 4 / 1e6\n",
    "    },\n",
    "    \"training_results\": {\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"final_train_loss\": training_history['train_loss'][-1] if training_history['train_loss'] else None,\n",
    "        \"final_val_loss\": training_history['val_loss'][-1] if training_history['val_loss'] else None,\n",
    "        \"total_epochs_trained\": len(training_history['train_loss'])\n",
    "    },\n",
    "    \"rl_results\": {\n",
    "        \"best_rl_reward\": best_rl_reward,\n",
    "        \"final_avg_reward\": np.mean(rl_history['episode_rewards'][-100:]) if rl_history['episode_rewards'] else None,\n",
    "        \"total_episodes_trained\": len(rl_history['episode_rewards'])\n",
    "    },\n",
    "    \"training_time\": {\n",
    "        \"total_training_time_hours\": total_training_time / 3600,\n",
    "        \"total_rl_time_hours\": total_rl_time / 3600\n",
    "    }\n",
    "}\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(training_summary, f, indent=2)\n",
    "print(f\"‚úÖ Training summary saved to {summary_path}\")\n",
    "\n",
    "print(f\"\\nüéâ All artifacts saved to {export_dir}\")\n",
    "print(f\"üìÅ Model artifacts include:\")\n",
    "print(f\"   - model.pt (trained model weights)\")\n",
    "print(f\"   - tokenizer.json (tokenizer configuration)\")\n",
    "print(f\"   - config.json (model configuration)\")\n",
    "print(f\"   - training_summary.json (training results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## üéØ Step 11: Model Inference and Testing\n",
    "\n",
    "Test the trained model with various inputs and demonstrate its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_for_inference"
   },
   "outputs": [],
   "source": [
    "# Load model for inference\n",
    "print(\"üéØ Loading model for inference...\")\n",
    "\n",
    "# Load the saved model\n",
    "model_checkpoint = torch.load(export_dir / \"model.pt\", map_location=device)\n",
    "model.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully for inference\")\n",
    "print(f\"üìä Best validation loss: {model_checkpoint['best_val_loss']:.4f}\")\n",
    "print(f\"üìä Best RL reward: {model_checkpoint['best_rl_reward']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_inference"
   },
   "outputs": [],
   "source": [
    "# Interactive inference function\n",
    "def generate_response(prompt, max_length=100, temperature=0.7, task_type=\"text\"):\n",
    "    \"\"\"Generate response for given prompt\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Tokenize input\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # Generate response\n",
    "        if task_type == \"code\":\n",
    "            # Add code token for code generation\n",
    "            input_ids = torch.cat([\n",
    "                torch.tensor([[tokenizer.code_token_id]]).to(device),\n",
    "                input_ids\n",
    "            ], dim=1)\n",
    "        \n",
    "        # Generate with sampling\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=input_ids.shape[1] + max_length,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        # Decode response\n",
    "        response = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Remove original prompt\n",
    "        response = response[len(prompt):].strip()\n",
    "        \n",
    "        return response\n",
    "\n",
    "print(\"üéØ Interactive Inference Ready!\")\n",
    "print(\"Use the generate_response() function to test the model.\")\n",
    "print(\"Example: generate_response('Hello, how are you?', max_length=50)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_examples"
   },
   "outputs": [],
   "source": [
    "# Test various examples\n",
    "print(\"üß™ Testing model with various examples...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Text generation examples\n",
    "text_examples = [\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"In a world where technology continues to evolve\",\n",
    "    \"The most important aspect of AGI is\",\n",
    "    \"When we think about multimodal AI\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìù Text Generation Examples:\")\n",
    "for i, example in enumerate(text_examples, 1):\n",
    "    print(f\"\\n{i}. Prompt: {example}\")\n",
    "    response = generate_response(example, max_length=80, temperature=0.7)\n",
    "    print(f\"   Response: {response}\")\n",
    "\n",
    "# Code generation examples\n",
    "code_examples = [\n",
    "    \"Write a function to calculate fibonacci numbers\",\n",
    "    \"Create a class for a binary tree\",\n",
    "    \"Implement a simple neural network\"\n",
    "]\n",
    "\n",
    "print(\"\\n\\nüíª Code Generation Examples:\")\n",
    "for i, example in enumerate(code_examples, 1):\n",
    "    print(f\"\\n{i}. Prompt: {example}\")\n",
    "    response = generate_response(example, max_length=150, temperature=0.3, task_type=\"code\")\n",
    "    print(f\"   Response:\\n```python\\n{response}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance_analysis"
   },
   "source": [
    "## üìä Step 12: Performance Analysis and Benchmarks\n",
    "\n",
    "Analyze model performance and compare with benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "performance_metrics"
   },
   "outputs": [],
   "source": [
    "# Performance analysis\n",
    "print(\"üìä Analyzing model performance...\")\n",
    "\n",
    "# Calculate model statistics\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model_size_mb = total_params * 4 / 1e6\n",
    "\n",
    "# Memory usage\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated() / 1e6\n",
    "    gpu_memory_reserved = torch.cuda.memory_reserved() / 1e6\n",
    "else:\n",
    "    gpu_memory_allocated = 0\n",
    "    gpu_memory_reserved = 0\n",
    "\n",
    "# Inference speed test\n",
    "print(\"‚ö° Testing inference speed...\")\n",
    "model.eval()\n",
    "test_prompt = \"The quick brown fox jumps over the lazy dog.\"\n",
    "input_ids = tokenizer.encode(test_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Warm up\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        _ = model(input_ids=input_ids)\n",
    "\n",
    "# Speed test\n",
    "import time\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for _ in range(100):\n",
    "        _ = model(input_ids=input_ids)\n",
    "end_time = time.time()\n",
    "\n",
    "avg_inference_time = (end_time - start_time) / 100\n",
    "tokens_per_second = input_ids.shape[1] / avg_inference_time\n",
    "\n",
    "# Print performance summary\n",
    "print(\"\\nüìä Performance Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model Architecture:\")\n",
    "print(f\"  - Total parameters: {total_params:,}\")\n",
    "print(f\"  - Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  - Model size: {model_size_mb:.1f} MB\")\n",
    "print(f\"  - Hidden dimension: {config.model.hidden_dim}\")\n",
    "print(f\"  - Number of layers: {config.model.num_layers}\")\n",
    "print(f\"  - Number of experts: {config.model.num_experts}\")\n",
    "print(f\"  - Top-k experts: {config.model.top_k}\")\n",
    "\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"  - Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"  - Training epochs: {len(training_history['train_loss'])}\")\n",
    "print(f\"  - Total training time: {total_training_time / 3600:.1f} hours\")\n",
    "\n",
    "print(f\"\\nRL Results:\")\n",
    "print(f\"  - Best RL reward: {best_rl_reward:.2f}\")\n",
    "print(f\"  - RL episodes: {len(rl_history['episode_rewards'])}\")\n",
    "print(f\"  - Total RL time: {total_rl_time / 3600:.1f} hours\")\n",
    "\n",
    "print(f\"\\nInference Performance:\")\n",
    "print(f\"  - Average inference time: {avg_inference_time*1000:.2f} ms\")\n",
    "print(f\"  - Tokens per second: {tokens_per_second:.1f}\")\n",
    "print(f\"  - GPU memory allocated: {gpu_memory_allocated:.1f} MB\")\n",
    "print(f\"  - GPU memory reserved: {gpu_memory_reserved:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_benchmarks"
   },
   "outputs": [],
   "source": [
    "# Comparison with benchmarks\n",
    "print(\"\\nüìà Model Comparison with Benchmarks:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define benchmark models for comparison\n",
    "benchmarks = {\n",
    "    \"GPT-2 Small\": {\n",
    "        \"params\": 124e6,\n",
    "        \"layers\": 12,\n",
    "        \"hidden_dim\": 768,\n",
    "        \"vocab_size\": 50257\n",
    "    },\n",
    "    \"GPT-2 Medium\": {\n",
    "        \"params\": 355e6,\n",
    "        \"layers\": 24,\n",
    "        \"hidden_dim\": 1024,\n",
    "        \"vocab_size\": 50257\n",
    "    },\n",
    "    \"SalesAI (Our Model)\": {\n",
    "        \"params\": total_params,\n",
    "        \"layers\": config.model.num_layers,\n",
    "        \"hidden_dim\": config.model.hidden_dim,\n",
    "        \"vocab_size\": config.model.vocab_size\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"{'Model':<20} {'Params':<12} {'Layers':<8} {'Hidden':<8} {'Vocab':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, specs in benchmarks.items():\n",
    "    params_m = specs[\"params\"] / 1e6\n",
    "    print(f\"{model_name:<20} {params_m:<12.1f} {specs['layers']:<8} {specs['hidden_dim']:<8} {specs['vocab_size']:<8}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Advantages of SalesAI:\")\n",
    "print(f\"  - Multimodal capabilities (text, vision, audio)\")\n",
    "print(f\"  - Mixture of Experts architecture for efficiency\")\n",
    "print(f\"  - Reinforcement learning integration\")\n",
    "print(f\"  - Meta-learning capabilities\")\n",
    "print(f\"  - Cross-modal attention mechanisms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## üéâ Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You have successfully trained a comprehensive multimodal generative AI model using the SalesAI framework. Here's what we accomplished:\n",
    "\n",
    "### ‚úÖ What We Built:\n",
    "\n",
    "1. **Complete Training Pipeline**: From data preparation to model deployment\n",
    "2. **Multimodal Model**: Text, vision, and audio processing capabilities\n",
    "3. **MoE Architecture**: Efficient mixture of experts implementation\n",
    "4. **RL Integration**: Autonomous learning through reinforcement learning\n",
    "5. **Comprehensive Evaluation**: Performance analysis and benchmarking\n",
    "\n",
    "### üöÄ Model Capabilities:\n",
    "\n",
    "- **Text Generation**: Human-like text generation with context awareness\n",
    "- **Code Generation**: Programming code generation with syntax accuracy\n",
    "- **Multimodal Processing**: Cross-modal understanding and generation\n",
    "- **Autonomous Learning**: Continuous improvement through RL\n",
    "- **Efficient Architecture**: MoE design for computational efficiency\n",
    "\n",
    "### üìä Training Results:\n",
    "\n",
    "- **Model Size**: {model_size_mb:.1f} MB\n",
    "- **Parameters**: {total_params:,}\n",
    "- **Best Validation Loss**: {best_val_loss:.4f}\n",
    "- **Best RL Reward**: {best_rl_reward:.2f}\n",
    "- **Training Time**: {total_training_time / 3600:.1f} hours\n",
    "\n",
    "### üîÆ Next Steps:\n",
    "\n",
    "1. **Model Deployment**: Deploy the trained model for production use\n",
    "2. **Fine-tuning**: Fine-tune on specific domains or tasks\n",
    "3. **Scaling**: Scale up the model with more parameters and data\n",
    "4. **Integration**: Integrate with applications and APIs\n",
    "5. **Research**: Explore advanced capabilities and improvements\n",
    "\n",
    "### üìÅ Saved Artifacts:\n",
    "\n",
    "All model artifacts have been saved to Google Drive:\n",
    "- **Model weights**: `/content/drive/MyDrive/SalesAI_Project/SalesAI_Model/model.pt`\n",
    "  - **Tokenizer**: `/content/drive/MyDrive/SalesAI_Project/SalesAI_Model/tokenizer.json`\n",
    "  - **Configuration**: `/content/drive/MyDrive/SalesAI_Project/SalesAI_Model/config.json`\n",
    "  - **Training summary**: `/content/drive/MyDrive/SalesAI_Project/SalesAI_Model/training_summary.json`\n",
    "\n",
    "### üéØ Usage Instructions:\n",
    "\n",
    "To use the trained model in other environments:\n",
    "\n",
    "```python\n",
    "# Load the model\n",
    "checkpoint = torch.load('model.pt', map_location='cuda')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Generate text\n",
    "response = generate_response('Your prompt here', max_length=100)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for using SalesAI! üöÄ**\n",
    "\n",
    "This notebook demonstrates the power of multimodal AI and the potential for creating AGI-like systems. The model you've trained represents a significant step toward more intelligent and versatile AI systems.\n",
    "\n",
    "**Built with ‚ù§Ô∏è by N.E.N (Nthuku Elijah Nzeli) and the SalesA Team**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "appendix"
   },
   "source": [
    "## üìö Appendix: Additional Resources\n",
    "\n",
    "### üîó Useful Links:\n",
    "\n",
    "- **SalesAI Repository**: [GitHub Link]\n",
    "- **PyTorch Documentation**: https://pytorch.org/docs/\n",
    "- **Hugging Face Transformers**: https://huggingface.co/docs/transformers/\n",
    "- **Google Colab**: https://colab.research.google.com/\n",
    "\n",
    "### üìñ Further Reading:\n",
    "\n",
    "1. **Mixture of Experts**: Switch Transformers paper\n",
    "2. **Multimodal AI**: CLIP, DALL-E, and GPT-4V research\n",
    "3. **Reinforcement Learning**: Deep Q-Networks and policy gradients\n",
    "4. **Meta-Learning**: Few-shot learning and rapid adaptation\n",
    "\n",
    "### üõ†Ô∏è Troubleshooting:\n",
    "\n",
    "**Common Issues and Solutions:**\n",
    "\n",
    "1. **Out of Memory Errors**:\n",
    "   - Reduce batch size\n",
    "   - Enable gradient checkpointing\n",
    "   - Use mixed precision training\n",
    "\n",
    "2. **Slow Training**:\n",
    "   - Ensure GPU is being used\n",
    "   - Check for CPU bottlenecks\n",
    "   - Optimize data loading\n",
    "\n",
    "3. **Poor Model Performance**:\n",
    "   - Increase training epochs\n",
    "   - Adjust learning rate\n",
    "   - Add more training data\n",
    "\n",
    "### üìû Support:\n",
    "\n",
    "For questions, issues, or contributions:\n",
    "- **GitHub Issues**: [Repository Issues Page]\n",
    "- **Email**: [Contact Email]\n",
    "- **Documentation**: [Project Documentation]\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! üéâ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
